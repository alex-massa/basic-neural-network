# basic-neural-network

A very basic neural network made from scratch, with a whole lot of code duplication.

## Structure

This is a shallow neural network, using only 3 layers: the input layer, a single hidden layer, and the output layer. \
It uses the technique of gradient descent with backpropagation to adjust its weights.

## Usage

The notebooks are intended to be used as a sandbox to play around with by tuning the various parameters and observe how performances differ.

## Reference

The book [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) by author Andrew W. Trask was used as a reference to build this neural network, although I wouldn't recommend reading through it in its entirety as it tends to fly over certain concepts and listings, and also contains some errors and inconsistencies, which can leave the reader confused (or I might just not be smart enough, a possibility I wouldn't rule out). \
As a consequence, the code might contain fragments that should be adjusted (or shouldn't be there in the first place), I simply didn't know better at the time of writing this. \
The first charapters were great though, and would recommend them for a beginner trying to grasp some of the basic concepts behind deep learning, so it's not all bad.
